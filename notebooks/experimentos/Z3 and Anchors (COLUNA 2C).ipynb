{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwlEKusEcBbw"
   },
   "source": [
    "# Installing Z3 and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dt8anHvhLwsn",
    "outputId": "13b6d0bc-f00b-4b50-99a2-9366ed28b2ce",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install z3-solver\\n!pip install pandas\\n!pip install numpy\\n!pip install sklearn\\n!pip install anchor-exp\\n'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    '''\n",
    "!pip install z3-solver\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install anchor-exp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "A1i4HEgVhKCN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from z3 import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX71r1djY-7L"
   },
   "source": [
    "# Training Linear and Polynomial SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TO6whMFhZ9yf"
   },
   "source": [
    "## Data Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "PW90CcDBHbaM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/column_2C.dat', sep=\" \", names=['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']=np.where(df['target']=='AB',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle',\n",
       "       'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = df.columns\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.03</td>\n",
       "      <td>22.55</td>\n",
       "      <td>39.61</td>\n",
       "      <td>40.48</td>\n",
       "      <td>98.67</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.06</td>\n",
       "      <td>10.06</td>\n",
       "      <td>25.02</td>\n",
       "      <td>29.00</td>\n",
       "      <td>114.41</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.83</td>\n",
       "      <td>22.22</td>\n",
       "      <td>50.09</td>\n",
       "      <td>46.61</td>\n",
       "      <td>105.99</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.30</td>\n",
       "      <td>24.65</td>\n",
       "      <td>44.31</td>\n",
       "      <td>44.64</td>\n",
       "      <td>101.87</td>\n",
       "      <td>11.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.71</td>\n",
       "      <td>9.65</td>\n",
       "      <td>28.32</td>\n",
       "      <td>40.06</td>\n",
       "      <td>108.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>47.90</td>\n",
       "      <td>13.62</td>\n",
       "      <td>36.00</td>\n",
       "      <td>34.29</td>\n",
       "      <td>117.45</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>53.94</td>\n",
       "      <td>20.72</td>\n",
       "      <td>29.22</td>\n",
       "      <td>33.22</td>\n",
       "      <td>114.37</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>61.45</td>\n",
       "      <td>22.69</td>\n",
       "      <td>46.17</td>\n",
       "      <td>38.75</td>\n",
       "      <td>125.67</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>45.25</td>\n",
       "      <td>8.69</td>\n",
       "      <td>41.58</td>\n",
       "      <td>36.56</td>\n",
       "      <td>118.55</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>33.84</td>\n",
       "      <td>5.07</td>\n",
       "      <td>36.64</td>\n",
       "      <td>28.77</td>\n",
       "      <td>123.95</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "0               63.03        22.55                  39.61         40.48   \n",
       "1               39.06        10.06                  25.02         29.00   \n",
       "2               68.83        22.22                  50.09         46.61   \n",
       "3               69.30        24.65                  44.31         44.64   \n",
       "4               49.71         9.65                  28.32         40.06   \n",
       "..                ...          ...                    ...           ...   \n",
       "305             47.90        13.62                  36.00         34.29   \n",
       "306             53.94        20.72                  29.22         33.22   \n",
       "307             61.45        22.69                  46.17         38.75   \n",
       "308             45.25         8.69                  41.58         36.56   \n",
       "309             33.84         5.07                  36.64         28.77   \n",
       "\n",
       "     pelvic_radius  degree_spondylolisthesis  target  \n",
       "0            98.67                     -0.25       1  \n",
       "1           114.41                      4.56       1  \n",
       "2           105.99                     -3.53       1  \n",
       "3           101.87                     11.21       1  \n",
       "4           108.17                      7.92       1  \n",
       "..             ...                       ...     ...  \n",
       "305         117.45                     -4.25       0  \n",
       "306         114.37                     -0.42       0  \n",
       "307         125.67                     -2.71       0  \n",
       "308         118.55                      0.21       0  \n",
       "309         123.95                     -0.20       0  \n",
       "\n",
       "[310 rows x 7 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "q5plsclR7tUW"
   },
   "outputs": [],
   "source": [
    "normalized_df=(df.values[:,:-1]-df.values[:,:-1].min())/(df.values[:,:-1].max()-df.values[:,:-1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMHNARKC8KJR",
    "outputId": "bbe60b5e-fc61-4253-dfb8-75efb51dfe0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.min(),normalized_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_targets(original_set):\n",
    "    original_unique = np.unique(original_set)\n",
    "    print(\"Original Targets: \",original_unique,\"\\nDesired Targets: [-1,1]\")\n",
    "    print(\"Is original the desired [1,-1]? \", np.array_equiv(original_unique,np.array([-1,1])))\n",
    "    if not np.array_equiv(original_unique,np.array([-1,1])):\n",
    "        if 1 in original_unique:\n",
    "            print(\"1 exists in dataset\")\n",
    "            new = np.select([original_set == original_unique[0]],[-1],original_set)\n",
    "        elif -1 in original_unique:\n",
    "            print(\"-1 exists in dataset\")\n",
    "            new = np.select([original_set == original_unique[1]],[1],original_set)\n",
    "        else:\n",
    "            print(\"Neither exists in dataset\")\n",
    "            new = np.select([original_set == original_unique[0],original_set == original_unique[1]],[-1,1],original_set)\n",
    "        #indexes = original_set[np.where(original_set == unique_elems[0])]\n",
    "        print(\"New datasets consists of: \",np.unique(new))\n",
    "        return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Targets:  [0 1] \n",
      "Desired Targets: [-1,1]\n",
      "Is original the desired [1,-1]?  False\n",
      "1 exists in dataset\n",
      "New datasets consists of:  [-1  1]\n"
     ]
    }
   ],
   "source": [
    "targets = check_targets(df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbakFrFRaCKb"
   },
   "source": [
    "## Data Separation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "qI2dGmVBh4Sq"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_df, targets, test_size=0.3,random_state=107) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_classifier(kernel_type='linear'):\n",
    "    return svm.SVC(kernel=kernel_type)\n",
    "def create_poly_classifier(kernel_type='poly',my_degree=2,my_gamma=1/6):\n",
    "    return svm.SVC(kernel=kernel_type, degree = my_degree,gamma=my_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx90Sjfwh9cz",
    "outputId": "565c216c-c6e3-48bf-a20b-c64f577ab7f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear: 0.6559139784946236\n"
     ]
    }
   ],
   "source": [
    "clf = create_linear_classifier()\n",
    "#poly = create_poly_classifier('poly',2,1/(X_train.var() * len(X_train[0])))\n",
    "\n",
    "#Train the models using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "#poly.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "#poly_y_pred = poly.predict(X_test)\n",
    "print(\"Accuracy Linear:\", metrics.accuracy_score(y_test, y_pred))\n",
    "#print(\"Accuracy Poly:\", metrics.accuracy_score(y_test, poly_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjIMKtJWiPAl",
    "outputId": "d9db7a40-e7b2-46aa-e558-a11d647d5d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training: 0.6866359447004609\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "#poly_pred_train = poly.predict(X_train)\n",
    "print(\"Accuracy on Training:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "#print(\"Accuracy on Training:\", metrics.accuracy_score(y_train, poly_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3lOiqOAaJpe"
   },
   "source": [
    "## SVM Decision Function For The First Element of Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igzG9IldBYWR",
    "outputId": "26b7faad-4c09-4561-c37d-bdba35c42e7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2768692235824575"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sum (coef @ sup_vec @ X[index] + bias)\n",
    "((clf.dual_coef_ @ clf.support_vectors_) @ X_train[0].reshape(1, len(X_train[0])).T + clf.intercept_)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(poly.dual_coef_ @ (((poly.support_vectors_ @ X_train[0].reshape(1, len(X_train[0])).T) * poly.gamma + poly.coef0) ** poly.degree) + poly.intercept_)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DualCoef / Support Vectors / X_Train.T Reshaped / Intercept (bias)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1, 136), (136, 6), (6, 1), (1,))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVM Decision Function\n",
    "print(\"DualCoef / Support Vectors / X_Train.T Reshaped / Intercept (bias)\")\n",
    "clf.dual_coef_.shape, clf.support_vectors_.shape, X_train[0].reshape(1, len(X_train[0])).T.shape, clf.intercept_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial SVM Decision Function\n",
    "#print(\"DualCoef / Support Vectors / X_Train.T Reshaped / Gamma / Coef0 / Degree / Intercept (bias)\")\n",
    "#poly.dual_coef_.shape, poly.support_vectors_.shape, X_train[0].reshape(1, len(X_train[0])).T.shape,poly.gamma, poly.coef0, poly.degree, poly.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZOA8ZXQZIH2",
    "tags": []
   },
   "source": [
    "# Defining Thresholds and Finding Rejecteds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limits(classifier,data):\n",
    "    dec_fun = classifier.decision_function(data)\n",
    "    lim_pos = dec_fun[np.argmax(dec_fun)]\n",
    "    lim_neg = dec_fun[np.argmin(dec_fun)]\n",
    "    return dec_fun, lim_pos, lim_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresholds(decfun,t1,t2,wr,chosen_min='EWRR'):\n",
    "    solution = {'WR':0,'T1':0, 'T2':0,'E':0,'R':0,'EWRR':0}\n",
    "    index = None\n",
    "    n_elements = decfun.shape[0]\n",
    "    for i,wr_ in enumerate(wr):\n",
    "      for j in range(0,len(t1)):\n",
    "        #Get Number of Rejected\n",
    "        positive_indexes = np.where(decfun >= t1[j])\n",
    "        negative_indexes = np.where(decfun < t2[j])\n",
    "        rejected_indexes = np.where((decfun < t1[j]) & (decfun >= t2[j]))\n",
    "        R = rejected_indexes[0].shape[0]\n",
    "        #np.array(positive_indexes).shape,np.array(negative_indexes).shape, R\n",
    "\n",
    "        #Get Number of Misclassifications\n",
    "        class_p = y_train[positive_indexes]\n",
    "        class_n = y_train[negative_indexes]\n",
    "        error_p = np.where(class_p == np.unique(y_train)[0])[0].shape[0]\n",
    "        error_n = np.where(class_n == np.unique(y_train)[1])[0].shape[0]\n",
    "        E = (error_p + error_n)/(n_elements - R)\n",
    "        #print(\"T1 \",round(t1[j],4),\"T2 \",round(t2[j],4),\"E\",round(E,4),\"Rej\",R,\"Pos \", positive_indexes[0].shape[0], \"Neg \",negative_indexes[0].shape[0])\n",
    "        if chosen_min=='R':\n",
    "            if (i == 0 and i == j) or R < solution['R']:\n",
    "                solution['WR'] = wr_\n",
    "                solution['T1'] = t1[j]\n",
    "                solution['T2'] = t2[j]\n",
    "                solution['E'] = E\n",
    "                solution['R'] = R\n",
    "                solution['EWRR'] = E + wr_ * R\n",
    "        elif chosen_min=='E':\n",
    "            if (i == 0 and i == j) or E < solution['E']:\n",
    "                solution['WR'] = wr_\n",
    "                solution['T1'] = t1[j]\n",
    "                solution['T2'] = t2[j]\n",
    "                solution['E'] = E\n",
    "                solution['R'] = R\n",
    "                solution['EWRR'] = E + wr_ * R\n",
    "        elif chosen_min=='EWRR':\n",
    "            if (i == 0 and i == j) or (E + wr_ * R) < solution['EWRR']:\n",
    "                solution['WR'] = wr_\n",
    "                solution['T1'] = t1[j]\n",
    "                solution['T2'] = t2[j]\n",
    "                solution['E'] = E\n",
    "                solution['R'] = R\n",
    "                solution['EWRR'] = E + wr_ * R\n",
    "        else:\n",
    "            return 'Chosen option \"' +chosen_min+'\" is invalid'\n",
    "    print('Thresholds by min(',chosen_min,') from solution: ',solution)\n",
    "    return solution['T1'], solution['T2']      \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indexes(decfun,t1,t2):\n",
    "    positive_indexes = np.where(decfun >= t1)[0]\n",
    "    negative_indexes = np.where(decfun < t2)[0]\n",
    "    rejected_indexes = np.where((decfun < t1) & (decfun >= t2))[0]\n",
    "    R = rejected_indexes.shape[0]\n",
    "    return positive_indexes,negative_indexes,rejected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresholds_and_indexes(classifier,data,wr = None):  \n",
    "    dec_fun,lim_pos,lim_neg = limits(classifier,data)\n",
    "    print(\"Superior Limit: \",lim_pos,\"\\nInferior Limit: \",lim_neg)\n",
    "    if wr == None:\n",
    "        wr = [0.04, 0.08, 0.12, 0.16, 0.2, 0.24, 0.28, 0.32, 0.36, 0.4, 0.44, 0.48]\n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    for i in range (1,101):\n",
    "      t1.append(0.01*i*lim_pos)\n",
    "      t2.append(0.01*i*lim_neg)  \n",
    "    T1,T2 = find_thresholds(dec_fun,t1,t2,wr)\n",
    "    pos_idx,neg_idx,rej_idx = find_indexes(dec_fun,T1,T2)\n",
    "    return T1, T2, pos_idx, neg_idx, rej_idx,lim_pos,lim_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkcUd3eZ9wQx"
   },
   "source": [
    "# Implementing SVM function for Z3 Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvhIKaB3fSBv"
   },
   "source": [
    "## Z3 Decision Function Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "8iDd2odTfUb-"
   },
   "outputs": [],
   "source": [
    "np.RealVal = np.vectorize(RealVal) \n",
    "np.RealVector = np.vectorize(RealVector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_z3_conversion(classifier,training_set):\n",
    "    z3_dual_coef = np.RealVal(classifier.dual_coef_)\n",
    "    z3_support_vectors = np.RealVal(classifier.support_vectors_)\n",
    "    z3_intercept_ = np.RealVal(classifier.intercept_)\n",
    "    z3_X_Train = np.RealVector('x',training_set.shape[1])\n",
    "    if classifier.kernel == 'poly':\n",
    "        z3_gamma = np.RealVal(classifier.gamma)\n",
    "        z3_coef0 = np.RealVal(classifier.coef0)\n",
    "        z3_degree = np.RealVal(classifier.degree)\n",
    "        return z3_dual_coef,z3_support_vectors,z3_intercept_,z3_X_Train, z3_gamma,z3_coef0,z3_degree\n",
    "    return z3_dual_coef,z3_support_vectors,z3_intercept_,z3_X_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "it9FGkScC0p_"
   },
   "source": [
    "# Z3 with Reject Option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF_vwBRveDln",
    "tags": []
   },
   "source": [
    "## Explaining the Classifier's Decision Function and Finding Relevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z3_explanation(classifier,t1, t2, X, z3_coef, z3_sup_vec, z3_X, z3_intercept, reject_indexes,sup_lim,inf_lim,\n",
    "                   z3_gamma = None, z3_coef0 = None, z3_degree = None, show_values=True, min=0,max=1,positive=False,negative=False,rejected=False):\n",
    "    elapsed_time = []\n",
    "    relevant = []\n",
    "    irrelevant = []\n",
    "    global_values = []\n",
    "    print(\"Number of Instances: \", len(reject_indexes))\n",
    "    solver = Solver()\n",
    "    if classifier.kernel=='linear':\n",
    "        print(\"Classifier: Linear\")\n",
    "        if rejected:\n",
    "            print(\"Declared: Rejected Instances\")\n",
    "            solver.add(Or(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] >= t1,\n",
    "                          ((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] < t2))\n",
    "        elif positive:\n",
    "            print(\"Declared: Positive Instances\")\n",
    "            solver.add(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] < t1)\n",
    "        elif negative:\n",
    "            print(\"Declared: Negative Instances\")\n",
    "            solver.add(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] >= t2)\n",
    "        else:\n",
    "            print(\"WARNING: Must declare if are positive,negative or rejected instances!\")\n",
    "        solver.add(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] >= inf_lim)\n",
    "        solver.add(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] <= sup_lim)\n",
    "    elif classifier.kernel=='poly':\n",
    "        print(\"Classifier: Polynomial\")\n",
    "        solver.add(Or(((z3_dual_coef @ (((z3_support_vectors @ z3_X.reshape(1, len(z3_X)).T) * z3_gamma + z3_coef0) ** z3_degree) + z3_intercept_)[0][0] >= t1),\n",
    "                      (z3_dual_coef @ (((z3_support_vectors @ z3_X.reshape(1, len(z3_X)).T) * z3_gamma + z3_coef0) ** z3_degree) + z3_intercept_)[0][0] < t2))\n",
    "    for j in range(0, len(z3_X)):\n",
    "        solver.add(z3_X[j] >= min)\n",
    "        solver.add(z3_X[j] <= max)\n",
    "    solver.push()\n",
    "    for i in range(0, len(reject_indexes)):\n",
    "        # Add Assertions for 0<= feature <= 1\n",
    "        index_list = list(range(len(z3_X)))\n",
    "        unsat_list = []\n",
    "        sat_list = []\n",
    "        values = []\n",
    "\n",
    "        # Select a feature and unfix it\n",
    "        start = time.perf_counter()\n",
    "        for z in range(0, len(z3_X)):\n",
    "            \n",
    "            for j in range(0, len(z3_X)):\n",
    "                if j != z and j in index_list:  # Choose one to check influence\n",
    "                    solver.add(z3_X[j] == X[reject_indexes[i]][j])            \n",
    "            check = solver.check()\n",
    "            if check == sat:\n",
    "                model = solver.model()\n",
    "                value = model[z3_X[z]].numerator_as_long() / model[z3_X[z]].denominator_as_long()\n",
    "                sat_list.append(z)\n",
    "                values.append(value)\n",
    "                if show_values:\n",
    "                    print('i = ', i, z, check, X[reject_indexes[i]][z], value)\n",
    "            else:\n",
    "                unsat_list.append(z)\n",
    "                index_list.remove(z)\n",
    "                if show_values:\n",
    "                    print('i = ', i, z, check)\n",
    "            \n",
    "            solver.pop()\n",
    "            solver.push()\n",
    "        elapsed_time.append(time.perf_counter()  - start)    \n",
    "        print(\"Finished \", i)\n",
    "        relevant.append(sat_list)\n",
    "        irrelevant.append(unsat_list)\n",
    "        global_values.append(values)\n",
    "        # print(\"Relevant: \",sat_list, '\\nUnsat List: ',unsat_list,'\\n')      \n",
    "    for i in range(0, len(relevant)):\n",
    "        if (show_values):\n",
    "            print('Instance ', i, '\\nRelevant Features: ', relevant[i], '\\nValues: ', global_values[i], '\\nIrrelevant Features: ',\n",
    "                  irrelevant[i], '\\nElapsed time: ',elapsed_time[i],'seconds\\n\\n')\n",
    "    \n",
    "    print(\"Tamanho médio de explicação: \",sum(len(x) for x in relevant)/len(relevant),\" - Custo médio: \",round(sum(elapsed_time)/len(elapsed_time),5),\"seg(s)\")        \n",
    "    return relevant, irrelevant, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Linear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get thresholds and the rejected for Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superior Limit:  1.4216456569456146 \n",
      "Inferior Limit:  0.7510107954487126\n",
      "Thresholds by min( EWRR ) from solution:  {'WR': 0.04, 'T1': 0.014216456569456146, 'T2': 0.007510107954487127, 'E': 0.31336405529953915, 'R': 0, 'EWRR': 0.31336405529953915}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.014216456569456146, 0.007510107954487127, 217, 0, 0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1,T2, positive_indexes,negative_indexes,rejected_indexes,lim_pos,lim_neg = find_thresholds_and_indexes(clf,X_train)\n",
    "T1,T2, positive_indexes.shape[0],negative_indexes.shape[0],rejected_indexes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get Z3's equivalent to linear classifier's decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3_dual_coef,z3_support_vectors,z3_intercept_,z3_X_Train = to_z3_conversion(clf,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_linear_relevant = []\n",
    "rejected_linear_irrelevant = []\n",
    "positive_linear_relevant = []\n",
    "positive_linear_irrelevant = []\n",
    "negative_linear_relevant = []\n",
    "negative_linear_irrelevant = []\n",
    "rejected_elapsed_time = []\n",
    "positive_elapsed_time = []\n",
    "negative_elapsed_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(rejected_indexes)!=0:\n",
    "    if len(rejected_indexes)>=50:\n",
    "        rejected_linear_relevant, rejected_linear_irrelevant, rejected_elapsed_time = z3_explanation(clf,T1,T2,X_train,z3_dual_coef,z3_support_vectors,z3_X_Train,z3_intercept_,rejected_indexes[0:50],\n",
    "                                                                          sup_lim=lim_pos,inf_lim=lim_neg,show_values=False, rejected = True)\n",
    "    else:\n",
    "        rejected_linear_relevant, rejected_linear_irrelevant, rejected_elapsed_time = z3_explanation(clf,T1,T2,X_train,z3_dual_coef,z3_support_vectors,z3_X_Train,z3_intercept_,rejected_indexes,\n",
    "                                                                          sup_lim=lim_pos,inf_lim=lim_neg,show_values=False, rejected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Instances:  50\n",
      "Classifier: Linear\n",
      "Declared: Positive Instances\n",
      "Finished  0\n",
      "Finished  1\n",
      "Finished  2\n",
      "Finished  3\n",
      "Finished  4\n",
      "Finished  5\n",
      "Finished  6\n",
      "Finished  7\n",
      "Finished  8\n",
      "Finished  9\n",
      "Finished  10\n",
      "Finished  11\n",
      "Finished  12\n",
      "Finished  13\n",
      "Finished  14\n",
      "Finished  15\n",
      "Finished  16\n",
      "Finished  17\n",
      "Finished  18\n",
      "Finished  19\n",
      "Finished  20\n",
      "Finished  21\n",
      "Finished  22\n",
      "Finished  23\n",
      "Finished  24\n",
      "Finished  25\n",
      "Finished  26\n",
      "Finished  27\n",
      "Finished  28\n",
      "Finished  29\n",
      "Finished  30\n",
      "Finished  31\n",
      "Finished  32\n",
      "Finished  33\n",
      "Finished  34\n",
      "Finished  35\n",
      "Finished  36\n",
      "Finished  37\n",
      "Finished  38\n",
      "Finished  39\n",
      "Finished  40\n",
      "Finished  41\n",
      "Finished  42\n",
      "Finished  43\n",
      "Finished  44\n",
      "Finished  45\n",
      "Finished  46\n",
      "Finished  47\n",
      "Finished  48\n",
      "Finished  49\n",
      "Tamanho médio de explicação:  0.0  - Custo médio:  0.00529 seg(s)\n"
     ]
    }
   ],
   "source": [
    "if len(positive_indexes)!=0:\n",
    "    if len(positive_indexes)>=50:\n",
    "        positive_linear_relevant, positive_linear_irrelevant, positive_elapsed_time = z3_explanation(clf,T1,T2,X_train,z3_dual_coef,z3_support_vectors,z3_X_Train,z3_intercept_,positive_indexes[0:50],\n",
    "                                                                          sup_lim=lim_pos,inf_lim=lim_neg,show_values=False, positive = True)\n",
    "    else:\n",
    "        positive_linear_relevant, positive_linear_irrelevant, positive_elapsed_time = z3_explanation(clf,T1,T2,X_train,z3_dual_coef,z3_support_vectors,z3_X_Train,z3_intercept_,positive_indexes,\n",
    "                                                                          sup_lim=lim_pos,inf_lim=lim_neg,show_values=False, positive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(negative_indexes)!=0:\n",
    "    if len(negative_indexes)>=50:\n",
    "        negative_linear_relevant, negative_linear_irrelevant, negative_elapsed_time = z3_explanation(clf,T1,T2,X_train,z3_dual_coef,z3_support_vectors,z3_X_Train,z3_intercept_,negative_indexes[0:50],\n",
    "                                                                          sup_lim=lim_pos,inf_lim=lim_neg,show_values=False, negative = True)\n",
    "    else:\n",
    "        negative_linear_relevant, negative_linear_irrelevant, negative_elapsed_time = z3_explanation(clf,T1,T2,X_train,z3_dual_coef,z3_support_vectors,z3_X_Train,z3_intercept_,negative_indexes,\n",
    "                                                                          sup_lim=lim_pos,inf_lim=lim_neg,show_values=False, negative = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Polynomial Classifier (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get thresholds and the rejected for Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T1,T2, positive_indexes,negative_indexes,rejected_indexes = find_thresholds_and_indexes(poly,X_train)\n",
    "#T1,T2, positive_indexes.shape[0],negative_indexes.shape[0],rejected_indexes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Z3's equivalent to Poly classifier's decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z3_dual_coef,z3_support_vectors,z3_intercept_,z3_X_Train,z3_gamma,z3_coef0,z3_degree = to_z3_conversion(poly,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#poly_relevant, poly_irrelevant = z3_explanation(poly,T1,T2,X_train,z3_dual_coef,z3_support_vectors,z3_X_Train,z3_intercept_,rejected_indexes[0:1], z3_gamma,z3_coef0,z3_degree, show_values=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF_vwBRveDln",
    "tags": []
   },
   "source": [
    "# Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF_vwBRveDln",
    "tags": []
   },
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Target Set with Reject Class == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ro_target_set(target_set,rejected_indexes):\n",
    "    target_set[rejected_indexes] = 0\n",
    "    return target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "ro_set = generate_ro_target_set(y_train,rejected_indexes)\n",
    "print(np.unique(ro_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for i in range(0,len(X_train[0])):\n",
    "    feature_list.append(str(i))\n",
    "feature_list = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    [-1,0,1],\n",
    "    feature_list,\n",
    "    X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_decfun(data,classifier=clf):\n",
    "    data = np.atleast_2d(data)\n",
    "    return ((classifier.dual_coef_ @ classifier.support_vectors_) @ data.T + classifier.intercept_)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_decfun_class(data,classifier=clf,Threshold_1=T1,Threshold_2=T2):\n",
    "    if svm_decfun(data) >= Threshold_1:\n",
    "        return np.array([2]) #class 1, since [-1, 0, 1]\n",
    "    elif svm_decfun(data) < Threshold_2:\n",
    "        return np.array([0]) #class -1\n",
    "    else:\n",
    "        return np.array([1]) #class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF_vwBRveDln",
    "tags": []
   },
   "source": [
    "## Explanation for 1 Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Anchors Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"idx = rejected_indexes[0]\\nnp.random.seed(1)\\nprint('Prediction: ', explainer.class_names[svm_decfun_class(X_train[idx])[0]])\\nexp = explainer.explain_instance(X_train[idx], svm_decfun_class, threshold=1)\""
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''idx = rejected_indexes[0]\n",
    "np.random.seed(1)\n",
    "print('Prediction: ', explainer.class_names[svm_decfun_class(X_train[idx])[0]])\n",
    "exp = explainer.explain_instance(X_train[idx], svm_decfun_class, threshold=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_instance_anchors(explainer,svm_decfun_class,X_train,indexes):\n",
    "    np.random.seed(1)\n",
    "    elapsed_time = []\n",
    "    exp = None\n",
    "    for idx in indexes:    \n",
    "        print('Prediction: ', explainer.class_names[svm_decfun_class(X_train[idx])[0]])\n",
    "        start = time.perf_counter()  \n",
    "        exp = explainer.explain_instance(X_train[idx], svm_decfun_class, threshold=1)\n",
    "        elapsed_time.append(time.perf_counter()-start)\n",
    "    return exp,elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_exp = None\n",
    "rejected_anchors_time = None\n",
    "if len(rejected_indexes)!=0:\n",
    "    if len(rejected_indexes)>=50:\n",
    "        rejected_exp,rejected_anchors_time = explain_instance_anchors(explainer,svm_decfun_class,X_train,rejected_indexes[0:50])\n",
    "    else:\n",
    "        rejected_exp,rejected_anchors_time = explain_instance_anchors(explainer,svm_decfun_class,X_train,rejected_indexes)\n",
    "if rejected_anchors_time != None and rejected_exp != None:    \n",
    "    print(\"Tempo Médio Anchors Rejeitados = \",sum(rejected_anchors_time)/len(rejected_anchors_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Prediction:  1\n",
      "Tempo Médio Anchors Positivos =  0.2623771939997823\n"
     ]
    }
   ],
   "source": [
    "positive_exp = None\n",
    "positive_anchors_time = None\n",
    "if len(positive_indexes)!=0:\n",
    "    if len(positive_indexes)>=50:\n",
    "        positive_exp,positive_anchors_time = explain_instance_anchors(explainer,svm_decfun_class,X_train,positive_indexes[0:50])\n",
    "    else:\n",
    "        positive_exp,positive_anchors_time = explain_instance_anchors(explainer,svm_decfun_class,X_train,positive_indexes)\n",
    "if positive_anchors_time != None and positive_exp != None:        \n",
    "    print(\"Tempo Médio Anchors Positivos = \",sum(positive_anchors_time)/len(positive_anchors_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_exp = None\n",
    "negative_anchors_time = None\n",
    "if len(negative_indexes)!=0:\n",
    "    if len(negative_indexes)>=50:\n",
    "        negative_exp,negative_anchors_time = explain_instance_anchors(explainer,svm_decfun_class,X_train,negative_indexes[0:50])\n",
    "    else:\n",
    "        negative_exp,negative_anchors_time = explain_instance_anchors(explainer,svm_decfun_class,X_train,negative_indexes)\n",
    "if negative_anchors_time != None and negative_exp != None:\n",
    "    print(\"Tempo Médio Anchors Negativos = \",sum(negative_anchors_time)/len(negative_anchors_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo Médio Anchors Positivos =  0.2623771939997823\n",
      "Tamanho Médio Total:  0.2623771939997823 sec\n"
     ]
    }
   ],
   "source": [
    "soma = 0\n",
    "tamanho = 0\n",
    "if rejected_anchors_time != None:\n",
    "    soma += sum(rejected_anchors_time)\n",
    "    tamanho += len(rejected_anchors_time)\n",
    "    print(\"Tempo Médio Anchors Rejeitados = \",sum(rejected_anchors_time)/len(rejected_anchors_time))\n",
    "if positive_anchors_time != None:\n",
    "    soma += sum(positive_anchors_time)\n",
    "    tamanho += len(positive_anchors_time)\n",
    "    print(\"Tempo Médio Anchors Positivos = \",sum(positive_anchors_time)/len(positive_anchors_time))\n",
    "if negative_anchors_time != None:\n",
    "    soma += sum(negative_anchors_time)\n",
    "    tamanho += len(negative_anchors_time)\n",
    "    print(\"Tempo Médio Anchors Negativos = \",sum(negative_anchors_time)/len(negative_anchors_time))      \n",
    "if tamanho != 0:\n",
    "    print(\"Tamanho Médio Total: \",soma/tamanho,'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF_vwBRveDln",
    "tags": []
   },
   "source": [
    "### Anchors Explanation on Z3 - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchors_to_z3_explanation(explainer, X, t1, t2, z3_coef, z3_sup_vec, z3_X, z3_intercept, indexes,\n",
    "                              z3_gamma=None, z3_coef0=None, z3_degree=None,min=0,max=1,positive=False,negative=False,rejected=False):\n",
    "    print('Started')\n",
    "    sat_var = 0\n",
    "    unsat_var = 0\n",
    "    np.random.seed(1)\n",
    "    solver = Solver()\n",
    "    if rejected:\n",
    "        print(\"Declared: Rejected Instances\")\n",
    "        solver.add(Or(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] >= t1,\n",
    "                      ((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] < t2))\n",
    "    elif positive:\n",
    "        print(\"Declared: Positive Instances\")\n",
    "        solver.add(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] < t1)\n",
    "    elif negative:\n",
    "        print(\"Declared: Negative Instances\")\n",
    "        solver.add(((z3_coef @ z3_sup_vec) @ z3_X.reshape(1, len(z3_X)).T + z3_intercept)[0][0] >= t2)\n",
    "    else:\n",
    "        print(\"WARNING: Must declare if are positive,negative or rejected instances!\")\n",
    "        return None\n",
    "    for j in range(0, len(z3_X)):\n",
    "        solver.add(z3_X[j] >= min)\n",
    "        solver.add(z3_X[j] <= max)\n",
    "    solver.push()\n",
    "    for idx in indexes:\n",
    "        print('Prediction: ', explainer.class_names[svm_decfun_class(X[idx])[0]])\n",
    "        exp = explainer.explain_instance(X[idx], svm_decfun_class, threshold=1)\n",
    "        print(exp.names())\n",
    "        print('Index = ', idx)      \n",
    "        for feature in np.unique(exp.features()):       \n",
    "            solver.add(z3_X[feature] == X[idx][feature])\n",
    "            print(\"Added restrictions: \",z3_X[feature],X[idx][feature])\n",
    "        print(solver.check(), ' for ', idx,'\\n')\n",
    "        if solver.check() == sat:\n",
    "            model = solver.model()\n",
    "            print(model)\n",
    "            sat_var +=1\n",
    "        else:\n",
    "            unsat_var +=1\n",
    "        print('\\n---------------\\n')\n",
    "        solver.pop()\n",
    "        solver.push()\n",
    "    print(\"Sat = \",sat_var,\"\\nUnsat = \",unsat_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_to_z3_explanation(explainer, X_train, T1, T2, z3_dual_coef, z3_support_vectors, z3_X_Train, z3_intercept_,rejected_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation for Multiple Instances - WIP"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Cópia de Slimmer Z3 SVM Solver.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
